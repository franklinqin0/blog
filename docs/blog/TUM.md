---
title: TUM course notes
date: 2021-04-12
categories:
  - study
tags:
  - tech
publish: false
---

<!-- more -->

## Compiler Construction

### Interpretation

No precomputation on program text necessary  
$\rightarrow$ no/small startup-overhead

More context information allows for specific aggressive optimization

### Compilation

Program components are analyzed once, during preprocessing, instead of multiple times during execution  
$\rightarrow$ smaller runtime-overhead

Runtime complexity of optimizations less important than in interpreter

Substitution Lemma:
atom level
semantic level

linear+algebra+refresher
Bayesian filtering ~ online learning

discriminative / generative model

ab\*a
syntax: specification
semantics: set of words

https://cs231n.github.io/convolutional-networks/

https://medium.com/@himanshuxd/activation-functions-sigmoid-relu-leaky-relu-and-softmax-basics-for-neural-networks-and-deep-8d9c70eed91e
