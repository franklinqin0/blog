---
title: TUM course notes
date: 2021-04-12
categories:
  - study
tags:
  - tech
publish: false
---

<!-- more -->

## Compiler Construction

### Interpretation

No precomputation on program text necessary  
$\rightarrow$ no/small startup-overhead

More context information allows for specific aggressive optimization

### Compilation

Program components are analyzed once, during preprocessing, instead of multiple times during execution  
$\rightarrow$ smaller runtime-overhead

Runtime complexity of optimizations less important than in interpreter

Substitution Lemma:
atom level
semantic level

linear+algebra+refresher
Bayesian filtering ~ online learning

discriminative / generative model

ab\*a
syntax: specification
semantics: set of words

https://cs231n.github.io/convolutional-networks/

[detailed overview of optimizers and their development](https://ruder.io/optimizing-gradient-descent)

[Tensors for Beginners 7: Linear Maps](https://youtu.be/dtvM-CzNe50)

[Xavier initialization](https://www.deeplearning.ai/ai-notes/initialization)

[transposed convolution](https://towardsdatascience.com/what-is-transposed-convolutional-layer-40e5e6e31c11)

[optuna](https://optuna.readthedocs.io/en/stable/tutorial/index.html)

supremum: lowest upper bound
infimum: greatest lower bound

Python UDP

https://pythontic.com/modules/socket/udp-client-server-example
https://wiki.python.org/moin/UdpCommunication
