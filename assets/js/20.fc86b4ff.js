(window.webpackJsonp=window.webpackJsonp||[]).push([[20],{531:function(e,t,a){"use strict";a.r(t);var s=a(2),n=Object(s.a)({},(function(){var e=this,t=e.$createElement,a=e._self._c||t;return a("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[a("div",{staticClass:"custom-block theorem"},[a("p",{staticClass:"title"},[e._v("THEOREM")]),a("p",[e._v("What, we asked, "),a("em",[e._v("wasn't")]),e._v(' the perceptron capable of? Dr. Rosenblatt threw up his hands, "Love," he said. "Hope. Despair. Human nature, in short. If we don\'t understand the human sex drive, why should we expect a machine to?"')]),e._v(" "),a("div",{staticClass:"custom-block right"},[a("p",[a("em",[e._v("New Yorker")]),e._v("'s interview with Frank Rosenblatt, the inventor of perceptron, the first AI algorithm")])])]),e._v(" "),a("p",[e._v("Artificial Intelligence (AI), computer programs that perform tasks with human intelligence, is prevalent in this world. There are programs that master Go and beat 18-time world champion; predict chemical reactions; recognize images; translate languages; drive cars. Computers will only be more prevalent in the foreseeable future. As AI becomes smarter, we naturally come up with the leading question: can computers think (like humans)?")]),e._v(" "),a("p",[e._v("Alan Turing, the father of computer science and AI, proposed a test for machine's ability to think: imitation game, or "),a("em",[e._v("Turing test")]),e._v("[1]. The test would rule computer as a human if "),a("eq",[a("span",{staticClass:"katex"},[a("span",{staticClass:"katex-mathml"},[a("math",{attrs:{xmlns:"http://www.w3.org/1998/Math/MathML"}},[a("semantics",[a("mrow",[a("mi",[e._v("C")])],1),a("annotation",{attrs:{encoding:"application/x-tex"}},[e._v("C")])],1)],1)],1),a("span",{staticClass:"katex-html",attrs:{"aria-hidden":"true"}},[a("span",{staticClass:"base"},[a("span",{staticClass:"strut",staticStyle:{height:"0.68333em","vertical-align":"0em"}}),a("span",{staticClass:"mord mathdefault",staticStyle:{"margin-right":"0.07153em"}},[e._v("C")])])])])]),e._v(", a human interrogator, cannot see the difference in response between player "),a("eq",[a("span",{staticClass:"katex"},[a("span",{staticClass:"katex-mathml"},[a("math",{attrs:{xmlns:"http://www.w3.org/1998/Math/MathML"}},[a("semantics",[a("mrow",[a("mi",[e._v("A")])],1),a("annotation",{attrs:{encoding:"application/x-tex"}},[e._v("A")])],1)],1)],1),a("span",{staticClass:"katex-html",attrs:{"aria-hidden":"true"}},[a("span",{staticClass:"base"},[a("span",{staticClass:"strut",staticStyle:{height:"0.68333em","vertical-align":"0em"}}),a("span",{staticClass:"mord mathdefault"},[e._v("A")])])])])]),e._v(", a computer, and player "),a("eq",[a("span",{staticClass:"katex"},[a("span",{staticClass:"katex-mathml"},[a("math",{attrs:{xmlns:"http://www.w3.org/1998/Math/MathML"}},[a("semantics",[a("mrow",[a("mi",[e._v("B")])],1),a("annotation",{attrs:{encoding:"application/x-tex"}},[e._v("B")])],1)],1)],1),a("span",{staticClass:"katex-html",attrs:{"aria-hidden":"true"}},[a("span",{staticClass:"base"},[a("span",{staticClass:"strut",staticStyle:{height:"0.68333em","vertical-align":"0em"}}),a("span",{staticClass:"mord mathdefault",staticStyle:{"margin-right":"0.05017em"}},[e._v("B")])])])])]),e._v(", a human. The decision, based on observation of responses, however, has multiple caveats.")],1),e._v(" "),a("p",[e._v("Firstly, the calibre of the interrogator is critical: naturally, the questions from a 5-year child vs. those from a philosopher would differ. Secondly, it is possible for "),a("eq",[a("span",{staticClass:"katex"},[a("span",{staticClass:"katex-mathml"},[a("math",{attrs:{xmlns:"http://www.w3.org/1998/Math/MathML"}},[a("semantics",[a("mrow",[a("mi",[e._v("C")])],1),a("annotation",{attrs:{encoding:"application/x-tex"}},[e._v("C")])],1)],1)],1),a("span",{staticClass:"katex-html",attrs:{"aria-hidden":"true"}},[a("span",{staticClass:"base"},[a("span",{staticClass:"strut",staticStyle:{height:"0.68333em","vertical-align":"0em"}}),a("span",{staticClass:"mord mathdefault",staticStyle:{"margin-right":"0.07153em"}},[e._v("C")])])])])]),e._v(" to rule computer as a human (false positive) and human as a computer (false negative). Thirdly, the number of possible questions asked by the interrogator is practically limited, so if the computer can remember a manual of limited questions and corresponding answers, it might fool the interrogator.")],1),e._v(" "),a("p",[e._v("Of course, the first and second problems can be resolved if there are sufficiently large number of interrogators and questions, so that a hypothesis test can be conducted to eliminate inaccuracies due to individual differences. The third question would lead to the "),a("em",[e._v("Chinese Room")]),e._v(" thought experiment[2].")]),e._v(" "),a("p",[e._v('The Chinese Room is a argument that if a computer can take an input of Chinese characters from a Chinese speaker outside the room, follow the instructions of a computer program, and produce an output of some Chinese characters as response, it can fool the Chinese speaker, pass the Turing test, and said to be able to "think". But does the computer "think" to produce the seemingly correct answers? Does it literally "understand" Chinese? Or is it merely simulating the ability to understand Chinese? The evident answers to the above questions can safely refute the effectiveness of Turing test, which concludes that AI could "think" if producing valid answers.')]),e._v(" "),a("p",[e._v("Before we proceed with more counter-arguements, let us consider the "),a("strong",[e._v('fundamental definition of "think"')]),e._v('. According to René Descartes, a "thinking thing" is "a thing that doubts, understands, affirms, denies, is willing, is unwilling, and also imagines and has sense perceptions"[?]. By his definition, a computer definitely can not "think", at least in the same way that humans do.')]),e._v(" "),a("p",[e._v('When a computer "listens" to music, "sees" an image, or "drives" a car, it receives input signals in time domain, converts them to frequency domain, uses some clever algorithms, such as deep learning, to classify or predict results based on training data. And if the training data is lacking or computing power is insufficient, the model cannot reach an optimal state and produce effective results.')]),e._v(" "),a("p",[e._v('These claims can be backed by real-world examples. In 2015, Google, a forerunner in commercial AI, was blamed for classifying some African Americans in a photo as gorillas[3]. Nearly 3 years later, the company still hasn’t really fixed anything, but simply blocked its image recognition algorithms from identifying gorillas altogether. Moreover, primates such as "gorilla", "chimp", "chimpanzee", and "monkey" remained blocked on Google Photos. Though there have been many impressive attempts on interpretablity[6]&[7], no simple and quick adjustment exists for AI algorithms with a black-box nature. Another example is Tesla\'s autopilot system which has caused multiple accidents already[4]. Yet Elon Musk boasted that Tesla engineers would "complete the basics of a completely autonomous driving system this year". The best algorithm we can analog to human intelligence, deep learning, would fail occasionally and not necessarily be as flexible as a human to make logical decision in a novel situation.')]),e._v(" "),a("p",[e._v('Can computers, given enough time, one day become a "thinking thing" by Descartes\' definition? To answer this question, we have to acknowledge the fundamental differences between humans and computers. Humans live in a physical world; perceive electromagnetic waves with narrow wavelengths bewteen 400nm and 780nm; have gender, family, lovers, and friends; have emotions like love, hatred, ecstasy, and sorrow; most importantly, humans can perceive so many different forms of data, namely, sight, sound, smell, taste, touch. In comparison, computers can only perceive data encoding in numbers. A phone chatbot mimics a female voice but is not female; it loves to eat ice cream but has no taste. There is no fundamental difference between the way an abacus, a mechanical computer, a electrical computer, or even a quantum computer in terms of data encoding: numbers. Even the state-of-the-art machine learning algorithms, such as BERT[?] in natural language processing, YOLO[?] in object detection, and ShuffleNet[?] in mobile applications, "think" in numbers and only excel at specific tasks (weak AI). '),a("strong",[e._v("Therefore, regretably or auspiciously, human intelligence (strong AI) may never befall as long as a numeric system is essential in the way computers store and process data.")])]),e._v(" "),a("p",[e._v('A further question can be raised naturally: if computers can never nurture the human nature and perceive data as we do, can they have "human intelligence"? We provide a positive answer with the help of brain-computer Interface (BCI), a bidirectional communication pathway between a wired brain and an external computer. There are non-invasive BCI\'s such as electroencephalography (EEG) that acquires brain wave signals and translates them into useful commands, and transcranial magnetic stimulation (TMS) that translates digital information into electric signals and feeds them to brains via stimulators. Another appraoch is to build an invasive BCI, such as electrocorticography (ECoG) or intracortical microelectrodes. Neuralink, a company founded by Elon Musk, introduced the new technology of minimally invasive brain implant that offers communication access and mobility to patients with spinal cord injuries. With more time and efforts from surgeons, neuroscientists, and engineers, we expect fervently that a symbiosis of humans and computers will bring unprecedented ease of acquiring knowledge without typing and conducting communications without talking.')]),e._v(" "),a("p",[e._v("With a synergy of humans' various senses and computers' strict logic, BCI can help computers \"think\" like humans. Then, there would no need for Turing test, because humans are computers, and computers are humans.")])])}),[],!1,null,null,null);t.default=n.exports}}]);