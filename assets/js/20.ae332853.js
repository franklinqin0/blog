(window.webpackJsonp=window.webpackJsonp||[]).push([[20],{531:function(e,a,t){"use strict";t.r(a);var n=t(2),s=Object(n.a)({},(function(){var e=this,a=e.$createElement,t=e._self._c||a;return t("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[t("p",[e._v("Artificial Intelligence (AI), computer programs performing tasks requiring human intelligence, is prevalent in this world. From 1957, when Frank Rosenblatt came up with the first machine learning algorithm, perceptron, a binary classifier which later proved to be unable to learn XOR function, to 2016, when DeepMind’s AlphaGo beat 18-time world champion Lee Sedol, AI undeniably has gone a long way and proved essential to our everyday life. There are programs that master Chess, Backgammon, Bridge, and Go; predict chemical reactions; recognize images; translate languages; read handwriting; write poems, compose music; draw paintings. There are also nearing but concerning applications such as self-driving cars, mass surveillance, and companion robots. We are living in a world that computers are prevalent and will only be more permeating in the future. Thus we naturally come up with the leading question: can computers think? And if so, how does that affect humans?")]),e._v(" "),t("p",[e._v("Alan Turing, the father of computer science and artificial intelligence, proposed a test of machine's ability to think: imitation game, or "),t("em",[e._v("Turing test")]),e._v("[1]. The test would rule computer as a human if "),t("eq",[t("span",{staticClass:"katex"},[t("span",{staticClass:"katex-mathml"},[t("math",{attrs:{xmlns:"http://www.w3.org/1998/Math/MathML"}},[t("semantics",[t("mrow",[t("mi",[e._v("C")])],1),t("annotation",{attrs:{encoding:"application/x-tex"}},[e._v("C")])],1)],1)],1),t("span",{staticClass:"katex-html",attrs:{"aria-hidden":"true"}},[t("span",{staticClass:"base"},[t("span",{staticClass:"strut",staticStyle:{height:"0.68333em","vertical-align":"0em"}}),t("span",{staticClass:"mord mathdefault",staticStyle:{"margin-right":"0.07153em"}},[e._v("C")])])])])]),e._v(", a human interrogator, cannot see the difference in response between player "),t("eq",[t("span",{staticClass:"katex"},[t("span",{staticClass:"katex-mathml"},[t("math",{attrs:{xmlns:"http://www.w3.org/1998/Math/MathML"}},[t("semantics",[t("mrow",[t("mi",[e._v("A")])],1),t("annotation",{attrs:{encoding:"application/x-tex"}},[e._v("A")])],1)],1)],1),t("span",{staticClass:"katex-html",attrs:{"aria-hidden":"true"}},[t("span",{staticClass:"base"},[t("span",{staticClass:"strut",staticStyle:{height:"0.68333em","vertical-align":"0em"}}),t("span",{staticClass:"mord mathdefault"},[e._v("A")])])])])]),e._v(", a computer, and player "),t("eq",[t("span",{staticClass:"katex"},[t("span",{staticClass:"katex-mathml"},[t("math",{attrs:{xmlns:"http://www.w3.org/1998/Math/MathML"}},[t("semantics",[t("mrow",[t("mi",[e._v("B")])],1),t("annotation",{attrs:{encoding:"application/x-tex"}},[e._v("B")])],1)],1)],1),t("span",{staticClass:"katex-html",attrs:{"aria-hidden":"true"}},[t("span",{staticClass:"base"},[t("span",{staticClass:"strut",staticStyle:{height:"0.68333em","vertical-align":"0em"}}),t("span",{staticClass:"mord mathdefault",staticStyle:{"margin-right":"0.05017em"}},[e._v("B")])])])])]),e._v(", a real human. This decision based on observation, however, has multiple caveats.")],1),e._v(" "),t("ol",[t("li",[e._v("The calibre of the interrogator is critical. Naturally, the questions from a 5-year child vs. those from a philosopher would differ.")]),e._v(" "),t("li",[e._v("There is a possibility for false positive and false negative.")]),e._v(" "),t("li",[e._v("The number of possible questions is practically limited, so if the computer can output based on a manual of limited questions and corresponding answers, it can fool the interrogator.")])]),e._v(" "),t("p",[e._v("Of course, the first and second problems can be resolved if there are enough interrogators and questions, so that a hypothesis test can be conducted to eliminate inaccuracies due to randomness. The third question would lead to the "),t("em",[e._v("Chinese Room")]),e._v(" thought experiment[2].")]),e._v(" "),t("p",[e._v('The Chinese Room is a argument that if a computer can take an input of Chinese characters from a Chinese speaker outside the room, follow the instructions of a computer program, and produce an output of some Chinese characters as response, it can fool the Chinese speaker, pass the Turing test, and said to be able to "think". But does the computer "think" to produce the seemingly correct answers? Does it literally "understand" Chinese? Or is it merely simulating the ability to understand Chinese? The evident answers to the above questions can safely refute the effectiveness of Turing test, which concludes that AI producing right answers could "think".')]),e._v(" "),t("p",[e._v('Before we proceed with further counter-arguements, let us consider the fundamental definition of "think". According to René Descartes, a "thinking thing" is "a thing that doubts, understands, affirms, denies, is willing, is unwilling, and also imagines and has sense perceptions". By his definition, a computer can definitely not "think", at least in the same way that humans do.')]),e._v(" "),t("p",[e._v('When a computer "listens" to music, "sees" an image, or "drives" a car, it receives input signals in time domain, converts them to frequency domain, uses some clever algorithms, such as deep learning, to classify or predict results based on training data. And if the training data is lacking or computing power is insufficient, the model cannot reach an optimal state and produce efficient results.')]),e._v(" "),t("p",[e._v('These claims can be backed by real-world examples. In 2015, Google, a forerunner in commercial AI, was criticized to classify some African Americans as gorillas[3]. Nearly 3 years later, the company still hasn’t really fixed anything, but simply blocked its image recognition algorithms from identifying gorillas altogether. Moreover, primates such as "gorilla", "chimp", "chimpanzee", and "monkey" remained blocked on Google Photos. This instance proves that a simple and quick adjustment has not existed for deep learning algorithms with a black-box nature (there are actually pretty pleasing attempts on interpretablity[6]&[7]). Another example is Tesla\'s autopilot system, a feature which claims to only assist driver rather than take full control, has had multiple accidents already[4]. Yet Elon Musk claimed that Tesla engineers would "complete the basics of a completely autonomous driving system". This instance proves that as deep learning, the best algorithm we can analog to human intelligence, would not necessarily be as flexible as a human to make logical decision in a novel situation.')]),e._v(" "),t("p",[e._v('Maybe we are too harsh on AI, a new invention less than 70 years of age. The human mind, in comparison, has evolved for millions of years[5]. Though we think we are "smarter" than our ancestors living in the Stone Age, our brains are not essentially different. That is to say, if a caveman travels to present-day society, given enough time, one could learn a natural language, adjust to a modern culture, and presumably get a college degree in physics given sufficient time. If modern humans cannot understand more quantum mechanics than the caveman after millenniums, how can we expect a AI program to "understand" love, hatred, sex drive, and family after decades?')]),e._v(" "),t("p",[e._v('Can computers one day, given enough time, become a "thinking thing" by Descartes\' definition? Humans live in a physical world, perceive electromagnetic waves whose wavelengths only reside bewteen 400nm and 780nm, have gender, family, lovers, and friends. What does these all mean for a computer? My phone chatbot talks with me in a male or female voice outputs merely a combination of human recordings; even the most state-of-the-art machine learning algorithms nowdays, such as BERT[?] in natural language processing, YOLO[?] in object detection, and ShuffleNet[?] in mobile applications, can only excel at specific tasks (weak AI). There is no fundamental difference between the way an abacus, a mechanical computer, a electrical computer, or even a quantum computer in terms of data encoding: numbers. Therefore, human intelligence (strong AI) may never befall, regretably or auspiciously, as long as a numeric system is essential in the way computers store and process data.')]),e._v(" "),t("p",[e._v('A further question can be raised naturally: if a computer cannot perceive as we do, is it still possible to have "human intelligence"?')])])}),[],!1,null,null,null);a.default=s.exports}}]);